axelera-model-format: 1.0.0

name: yolov7-tiny-coco-onnx

description: YOLOv7-tiny-v0.1 ONNX (COCO)
# converted from https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt with opset=12
# !python export.py --weights yolov7-tiny.pt --img-size 416 416 --grid

pipeline:
  - detections:
      model_name: yolov7-tiny-coco-onnx
      template_path: $AXELERA_FRAMEWORK/pipeline-template/yolo-letterbox.yaml
      postprocess:
        - decodeyolo:
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_class_agnostic: False
            nms_top_k: 300

models:
  yolov7-tiny-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov7-tiny.onnx
    weight_url: https://d1o2y3tc25j7ge.cloudfront.net/artifacts/model_cards/weights/yolo/object_detection/yolov7-tiny.onnx
    weight_md5: 06b81780b9d73b877f04935a54c9a518
    task_category: ObjectDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 416, 416]
    input_color_format: RGB
    num_classes: 80
    dataset: CocoDataset-COCO2017
    extra_kwargs:
      YOLO:
        anchors_path: training_yamls/yolov7-tiny.yaml
        anchors_url: https://d1o2y3tc25j7ge.cloudfront.net/artifacts/model_cards/weights/yolo/object_detection/cfgs/yolov7-tiny.yaml
        # from https://github.com/WongKinYiu/yolov7/raw/main/cfg/deploy/yolov7-tiny.yaml
        anchors_md5: 5d7693d4e3e151125a76c52c988b4a65
        #anchors: # or, specified explicitly
        #- [anchor, anchor, anchor]
        #- [anchor, anchor, anchor]
        #- [anchor, anchor, anchor]
        # strides: [8, 16, 32]  # specify if you are using a special version

datasets: # Python dataloader
  CocoDataset-COCO2017:
    class: ObjDataAdaptor
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    labels_path: $AXELERA_FRAMEWORK/ax_datasets/labels/coco.names
    # If using a custom dataset, comment out download year and add either
    # repr_imgs or cal_data for calibration and add val_data for validation.
    # You can use your existing training dataset as cal_data
    download_year: 2017
    repr_imgs_dir_path: $AXELERA_FRAMEWORK/data/coco2017_400_b680128
    repr_imgs_url: https://d1o2y3tc25j7ge.cloudfront.net/artifacts/data/coco/coco2017_repr400.zip
    repr_imgs_md5: b680128512392586e3c86b670886d9fa
    # relative/path/to/your/cal_custom.json or dir with darknet label txt files
    # cal_data: train2017-400.txt
    # val_data: val2017.txt
