axelera-model-format: 1.0.0

name: yolov8npose-coco-onnx

description: yolov8n pose estimation ultralytics v8.1.0, 640x640 (COCO)
# converted from https://github.com/ultralytics/ultralytics

pipeline:
  - keypoint_detections:
      model_name: yolov8npose-coco-onnx
      template_path: $AXELERA_FRAMEWORK/pipeline-template/yolopose-letterbox.yaml
      postprocess:
        - decodeyolopose:
            max_nms_boxes: 30000
            conf_threshold: 0.25
            nms_iou_threshold: 0.45
            nms_top_k: 300
            eval:
              conf_threshold: 0.001
              nms_iou_threshold: 0.65

models:
  yolov8npose-coco-onnx:
    class: AxONNXModel
    class_path: $AXELERA_FRAMEWORK/ax_models/base_onnx.py
    weight_path: weights/yolov8n-pose-v8.1.onnx
    weight_url: https://d1o2y3tc25j7ge.cloudfront.net/artifacts/model_cards/weights/yolo/keypoint_detection/yolov8n-pose-v8.1.onnx
    weight_md5: 67a56731f44db74079357437d37cb76d
    task_category: KeypointDetection
    input_tensor_layout: NCHW
    input_tensor_shape: [1, 3, 640, 640]
    input_color_format: RGB
    num_classes: 1
    dataset: CocoDataset-keypoint-COCO2017

datasets: # Python dataloader
  CocoDataset-keypoint-COCO2017:
    class: KptDataAdapter
    class_path: $AXELERA_FRAMEWORK/ax_datasets/objdataadapter.py
    data_dir_name: coco
    download_year: 2017
    # TODO: study which representative images are the best
    repr_imgs_dir_path: $AXELERA_FRAMEWORK/data/coco2017_400_b680128
    repr_imgs_url: https://d1o2y3tc25j7ge.cloudfront.net/artifacts/data/coco/coco2017_repr400.zip
    repr_imgs_md5: b680128512392586e3c86b670886d9fa
    # without val, will use the default coco2017 val set
    # val_data: dir with yolo label txt files or annotations/person_keypoints_val2017.json
    # if using COCO json format, please specify cal_img_dir / val_img_dir
    # val_img_dir_name: images/val2017
